
# Self-Refining LLM Chat â€“ Sketch v3

## Overview
Sketch v3 is the third iteration of the **Self-Refining LLM Chat System**, designed to overcome the stagnation observed in v2â€™s linear supervisor loop.  
This version introduces **multi-role orchestration** and a persistent **EvidenceStore** to ensure every round injects fresh sources, domain insights, and rigorous auditing.

---

## âœ¨ Features

- **Multi-Role Pipeline**
  - **Collector** â€“ gathers and structures search results into evidence packs.
  - **Editor** â€“ drafts coherent narrative answers with citations.
  - **Auditor** â€“ checks drafts against evidence, flags contradictions and gaps.
  - **Specialist** â€“ injects domain-specific insights and examples.
  - **Supervisor** â€“ scores drafts, enforces rubric, and decides continuation.

- **EvidenceStore**
  - Persistent storage of search results across rounds.
  - Structured schema with sources, summaries, contradictions, and gaps.
  - Accessible to all roles for traceability and auditability.

- **Dynamic Refinement**
  - Supervisor feedback drives query refinement.
  - Collector refreshes search with new keywords each round.
  - Prevents stagnation by continuously injecting new evidence.

- **Audit Trail**
  - Iteration history logs drafts, audits, reviews, and scores.
  - Markdown export includes final answer + role contributions.

- **Dashboard Integration**
  - Charts for score progression, token usage, and role impact.
  - Legends placed outside chart area for clarity.

---

## ðŸ§© Architecture

```
User Query
   â†“
Collector â†’ Evidence Pack â†’ EvidenceStore
   â†“
Editor â†’ Draft
   â†“
Auditor â†’ Gap Report
   â†“
Specialist â†’ Enriched Draft
   â†“
Supervisor â†’ Score + Feedback
   â†“
Loop Control â†’ Refine Query â†’ Collector refresh
```

---

## ðŸ“‚ EvidenceStore Schema

```json
{
  "query_id": "uuid",
  "round": 1,
  "timestamp": "2025-12-30T15:39:00Z",
  "sources": [
    {
      "source_id": "src_001",
      "title": "NeurIPS 2025 Program Overview",
      "snippet": "Startup & Innovation track...",
      "url": "https://neurips.cc/Conferences/2025",
      "date": "2025-12-01",
      "relevance_score": 0.92,
      "domain": "conference",
      "collector_notes": "High VC density."
    }
  ],
  "summary": {
    "bullet_points": [
      "NeurIPS 2025 includes Startup & Innovation track with VC pitch nights."
    ],
    "contradictions": [],
    "gaps": []
  }
}
```

---

## ðŸ”„ Iteration Loop

1. **Collector** â†’ runs search, stores results in EvidenceStore.  
2. **Editor** â†’ drafts narrative from latest evidence pack.  
3. **Auditor** â†’ checks draft against all sources, updates contradictions/gaps.  
4. **Specialist** â†’ enriches draft with domain insights.  
5. **Supervisor** â†’ scores draft, provides feedback, decides continuation.  
6. **Loop Control** â†’ refines query, Collector refreshes search, repeat until score â‰¥ 4 or max rounds.

---

## ðŸ“Š Lessons Learned from v2 â†’ v3

- **v2 Strengths**  
  - Compression kept token usage manageable.  
  - Supervisor rubric enforced professional tone.  
  - Debug + dashboard gave visibility into refinement quality.

- **v2 Limitations**  
  - Single generator role â†’ stagnation after ~10 rounds.  
  - Supervisor feedback repeated without injecting new evidence.  
  - Long loops plateaued instead of improving.

- **v3 Improvements**  
  - Multi-role specialization prevents stagnation.  
  - EvidenceStore ensures persistent, structured source injection.  
  - Auditor + Specialist roles add rigor and depth.  
  - Supervisor enforces rubric but now benefits from richer drafts.

---

## ðŸš€ Next Steps

- Implement `parse_sources()` to convert Collectorâ€™s raw text into structured JSON.  
- Run deep queries (e.g., AI safety controversies, investment strategy).  
- Benchmark v3 against v2: compare iteration scores, source diversity, and final draft quality.  
- Extend role library (e.g., Statistician, Legal Analyst) for domain-specific tasks.  
- Add Markdown export with embedded charts for full deep review.

---

## âœ… Status

Sketch v3 is **in development**.  
It represents a major architectural pivot from linear loops to multi-role orchestration with persistent evidence storage.  
This version aims to deliver **professional-quality, self-defining answers** that evolve meaningfully across rounds.


